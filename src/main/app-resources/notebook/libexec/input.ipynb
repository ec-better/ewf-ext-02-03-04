{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-ext-02-03-04 - NDVI anomalies of growing season time series per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI anomalies of growing season time series per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'NDVI anomalies of growing season time series per pixel'),\n",
    "                ('abstract', 'NDVI anomalies of growing season time series per pixel'),\n",
    "                ('id', 'ewf-ext-02-03-04')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON ((-8.864205 38.88616500000001, -8.864205 38.986165, -8.964205000000002 38.986165, -8.964205000000002 38.88616500000001, -8.864205 38.88616500000001))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'P001'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexAndApiKeys = dict([('id', 'indexAndApiKeys'),\n",
    "                        ('value', ''),\n",
    "                        ('title', 'index,apikey pairs'),\n",
    "                        ('abstract', 'index,apikey pairs'),\n",
    "                        ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "Agg and LTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_identifiers = ('LE07_difNdvi_P001_2015005_2015020.tif', 'LTA_LE07_difNdvi_P001_005-020_2015-2015.tif')\n",
    "input_identifiers = ('60C6662B91CEB188007C3809F852EC0FB0378E2E','1D976D213B24ABFA2CAA46870019E296CE47A06E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "Agg and LTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#input_references = ('https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=B02BEB4BAA63351C44F3DF2C9A6D8D116D089325', 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=442355F3238A8B5B9A016D3929ED42FCCF13C236')\n",
    "input_references = ('https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=60C6662B91CEB188007C3809F852EC0FB0378E2E', 'https://catalog.terradue.com/better-ext-02-03-03/search?format=atom&uid=1D976D213B24ABFA2CAA46870019E296CE47A06E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aux folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata from catalog\n",
    "def get_input_metadata (input_refs, apikeys):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        for index in apikeys:\n",
    "            if index in product_ref:\n",
    "                cat_index = index\n",
    "                cat_apikey = apikeys[index]\n",
    "        \n",
    "        # since the search is by identifier\n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,startdate,enddate,wkt,title',creds='{}:{}'.format(cat_index,cat_apikey))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata\n",
    "\n",
    "    \n",
    "def get_metadata(filepath):\n",
    "        \n",
    "    #pdb.set_trace()\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "        \n",
    "        print(type(product_array))\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "def get_matrix_list(image_list, mask_value = None):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        \n",
    "        if mask_value is not None:\n",
    "             product_array = np.ma.masked_values (product_array, mask_value)\n",
    "        \n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "\n",
    "def calc_anomaly(agg_file, LTA_file):\n",
    "    \n",
    "    \n",
    "    if agg_file and LTA_file:\n",
    "        \n",
    "        \n",
    "        agg_and_LTA = get_matrix_list([agg_file, LTA_file], -9999.)\n",
    "        print('Aggregation and LTA converted to matrices')\n",
    "                \n",
    "        \n",
    "        #anomaly_values = np.divide(agg_and_LTA[0] * 1.0, agg_and_LTA[1] * 1.0)\n",
    "        \n",
    "      \n",
    "        #anomaly_values = np.divide(agg_and_LTA[0] * 1.0, agg_and_LTA[1] * 1.0, out=np.zeros_like(agg_and_LTA[0]) - 9999.0, where=np.logical_and(agg_and_LTA[1]!=0, agg_and_LTA[0] > -9998, agg_and_LTA[1] > -9998) )\n",
    "        \n",
    "        anomaly_values = np.divide(agg_and_LTA[0] * 1.0, agg_and_LTA[1] * 1.0, out=np.zeros(agg_and_LTA[0].shape) - 9999.0, where=np.logical_and(agg_and_LTA[1]!=0, agg_and_LTA[0] > -9998, agg_and_LTA[1] > -9998) )\n",
    "        \n",
    "        anomaly_values = np.ma.masked_values (anomaly_values, -9999.0)\n",
    "        \n",
    "        #anomaly_values[(agg_and_LTA[0] == 0)] = 0\n",
    "        #anomaly_values[(agg_and_LTA[1] == 0)] = 0\n",
    "        \n",
    "        \n",
    "        #print(anomaly_values.data)\n",
    "        #print(anomaly_values2)\n",
    "        \n",
    "        \n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(agg_file)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #for file_ in file_list:\n",
    "        #    os.remove(file_)\n",
    "        \n",
    "        return anomaly_values, projection, geotransform, no_data_value, data_type\n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    if mask is not None and mask is not 0:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "\n",
    "    \n",
    "\n",
    "def write_anomaly_output(anomaly, output_folder, mission_name, stats_name, first_date, last_date, lta_start_year, lta_end_year, mask_no_value, regionOfInterest, roi_name, projection, geo_transform, no_data_value):\n",
    "    #image_number = (datetime.strptime(last_date, '%Y-%m-%d') - datetime.strptime(first_date, '%Y-%m-%d')).days\n",
    "    \n",
    "    \n",
    "    #filename =  output_folder + '/' + product_name + '_Anomaly_' + roi_name + '_N' + str(N_value) + '_' + aggregation + '_' + first_date + '_' + last_date + '_LTA' + str(lta_start_year) + '_' + str(lta_end_year) + '.tif'\n",
    "    \n",
    "    stats_period = first_date.strftime('%Y%j') + '_' + last_date.strftime('%Y%j')\n",
    "    LTA_period = str(lta_start_year) + '-' + str(lta_end_year)\n",
    "    \n",
    "    filename = '_'.join(['Anomaly', mission_name, stats_name, roi_name, stats_period, 'LTA', LTA_period])\n",
    "    \n",
    "    filename = os.path.join(output_folder, filename + '.tif')\n",
    "    \n",
    "    write_output_image(filename, anomaly, 'GTiff', gdal.GDT_Float32, mask_no_value, projection, geo_transform, no_data_value)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    date = datetime.datetime.strftime(date_str, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "#if not os.path.isdir(temp_folder):\n",
    "#    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reporter:status:2019-11-06T21:44:36.046726 [INFO   ] [user process] Getting metadata from catalog\n",
      "2019-11-06T21:44:36.046726 [INFO   ] [user process] Getting metadata from catalog\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better-ext-02-03-02\n",
      "better-ext-02-03-03\n"
     ]
    }
   ],
   "source": [
    "message = 'Getting metadata from catalog' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "\n",
    "# organize indexes and apikeys in a python dictionary\n",
    "indexAndApiKeys_splited = indexAndApiKeys['value'].split(',')\n",
    "apikeys = {}\n",
    "for idx,ele in enumerate(indexAndApiKeys_splited):\n",
    "    \n",
    "    if (idx % 2 == 0):\n",
    "        print(ele)\n",
    "        apikeys[ele] = indexAndApiKeys_splited[idx+1]\n",
    "        \n",
    "\n",
    "# get input data from catalog\n",
    "input_metadata = get_input_metadata (input_references, apikeys)\n",
    "\n",
    "\n",
    "\n",
    "input_metadata_LTA = input_metadata[input_metadata['title'].str.find('LTA') != -1]\n",
    "input_metadata_Agg = input_metadata[input_metadata['title'].str.find('LTA') == -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enclosure</th>\n",
       "      <th>enddate</th>\n",
       "      <th>identifier</th>\n",
       "      <th>self</th>\n",
       "      <th>startdate</th>\n",
       "      <th>title</th>\n",
       "      <th>wkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://store.terradue.com/better-ext-02-03-03...</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>1D976D213B24ABFA2CAA46870019E296CE47A06E</td>\n",
       "      <td>https://catalog.terradue.com/better-ext-02-03-...</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>Output LTA_LE07_cumulativeNdvi_P001_005-350_20...</td>\n",
       "      <td>POLYGON((-8.864205 38.886165,-8.864205 38.9861...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enclosure    enddate  \\\n",
       "1  https://store.terradue.com/better-ext-02-03-03... 2017-12-16   \n",
       "\n",
       "                                 identifier  \\\n",
       "1  1D976D213B24ABFA2CAA46870019E296CE47A06E   \n",
       "\n",
       "                                                self  startdate  \\\n",
       "1  https://catalog.terradue.com/better-ext-02-03-... 2015-01-05   \n",
       "\n",
       "                                               title  \\\n",
       "1  Output LTA_LE07_cumulativeNdvi_P001_005-350_20...   \n",
       "\n",
       "                                                 wkt  \n",
       "1  POLYGON((-8.864205 38.886165,-8.864205 38.9861...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_metadata_LTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enclosure</th>\n",
       "      <th>enddate</th>\n",
       "      <th>identifier</th>\n",
       "      <th>self</th>\n",
       "      <th>startdate</th>\n",
       "      <th>title</th>\n",
       "      <th>wkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://store.terradue.com/better-ext-02-03-02...</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>60C6662B91CEB188007C3809F852EC0FB0378E2E</td>\n",
       "      <td>https://catalog.terradue.com/better-ext-02-03-...</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>Output LE07_cumulativeNdvi_P001_2015005_201535...</td>\n",
       "      <td>POLYGON((-8.864205 38.886165,-8.864205 38.9861...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enclosure    enddate  \\\n",
       "0  https://store.terradue.com/better-ext-02-03-02... 2015-12-16   \n",
       "\n",
       "                                 identifier  \\\n",
       "0  60C6662B91CEB188007C3809F852EC0FB0378E2E   \n",
       "\n",
       "                                                self  startdate  \\\n",
       "0  https://catalog.terradue.com/better-ext-02-03-... 2015-01-05   \n",
       "\n",
       "                                               title  \\\n",
       "0  Output LE07_cumulativeNdvi_P001_2015005_201535...   \n",
       "\n",
       "                                                 wkt  \n",
       "0  POLYGON((-8.864205 38.886165,-8.864205 38.9861...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_metadata_Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LE07_cumulativeNdvi_P001_2015005_2015350.tif', 'LTA_LE07_cumulativeNdvi_P001_005-350_2015-2017.tif')\n"
     ]
    }
   ],
   "source": [
    "# get file paths\n",
    "filepath_agg = os.path.join(data_path, input_metadata_Agg['enclosure'].iloc[0].split('/')[-1])\n",
    "filepath_LTA = os.path.join(data_path, input_metadata_LTA['enclosure'].iloc[0].split('/')[-1])\n",
    "\n",
    "print(filepath_agg,filepath_LTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LE07', 'cumulativeNdvi', 'P001')\n",
      "2015-01-05 00:00:00\n",
      "2015-12-16 00:00:00\n",
      "['LTA', 'LE07', 'cumulativeNdvi', 'P001', '005-350', '2015-2017']\n",
      "2015\n",
      "2017\n",
      "LE07_cumulativeNdvi_P001_2015005_2015350.tif\n",
      "LTA_LE07_cumulativeNdvi_P001_005-350_2015-2017.tif\n",
      "Aggregation and LTA converted to matrices\n",
      "Anomaly_LE07_cumulativeNdvi_P001_2015005_2015350_LTA_2015-2017.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reporter:status:2019-11-06T21:44:44.043304 [INFO   ] [user process] Computing Anomaly\n",
      "2019-11-06T21:44:44.043304 [INFO   ] [user process] Computing Anomaly\n",
      "reporter:status:2019-11-06T21:44:44.052888 [INFO   ] [user process] Writing anomaly image\n",
      "2019-11-06T21:44:44.052888 [INFO   ] [user process] Writing anomaly image\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if isinstance(input_identifiers, str):\n",
    "    input_identifiers = [input_identifiers]\n",
    "\n",
    "region_of_interest = regionOfInterest['value']\n",
    "name_of_region = nameOfRegion['value']\n",
    "\n",
    "\n",
    "# get metadata from catalog metadata (Agg and LTA)\n",
    "\n",
    "# Agg\n",
    "\n",
    "file_name_elements = os.path.basename(filepath_agg).split('.')[0].split('_')\n",
    "#['LST', 'SouthernAfrica', 'N3', 'averages', '2015-01-01', '2015-01-21']\n",
    "#first_date = file_name_elements[-2]\n",
    "#last_date = file_name_elements[-1]\n",
    "misson_name = file_name_elements[0]\n",
    "stats_name = file_name_elements[1]\n",
    "aoi_name = file_name_elements[2]\n",
    "\n",
    "#LE07_difNdvi_P001_2015005_2015020.tif\n",
    "print(misson_name, stats_name, aoi_name)\n",
    "\n",
    "#first_date = input_metadata_Agg['startdate'].iloc[0].strftime('%Y-%m-%d')\n",
    "#last_date = input_metadata_Agg['enddate'].iloc[0].strftime('%Y-%m-%d')\n",
    "\n",
    "first_date = datetime.datetime.strptime(file_name_elements[3], \"%Y%j\")\n",
    "last_date = datetime.datetime.strptime(file_name_elements[4], \"%Y%j\")\n",
    "\n",
    "\n",
    "#first_date = first_date.strftime('%Y-%m-%d')\n",
    "#last_date = last_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(first_date)\n",
    "print(last_date)\n",
    "\n",
    "\n",
    "# LTA\n",
    "\n",
    "file_name_elements = os.path.basename(filepath_LTA).split('.')[0].split('_')\n",
    "\n",
    "\n",
    "#start_year = str(input_metadata_LTA['startdate'].iloc[0].year)\n",
    "#end_year = str(input_metadata_LTA['enddate'].iloc[0].year)\n",
    "\n",
    "start_year = file_name_elements[5].split('-')[0]\n",
    "end_year = file_name_elements[-1].split('-')[1]\n",
    "\n",
    "print(file_name_elements)\n",
    "\n",
    "stats_name_LTA = file_name_elements[2]\n",
    "\n",
    "\n",
    "print(start_year)\n",
    "print(end_year)\n",
    "\n",
    "\n",
    "\n",
    "print(filepath_agg)\n",
    "print(filepath_LTA)        \n",
    "\n",
    "message = 'Computing Anomaly' \n",
    "ciop.log('INFO', message)\n",
    "    \n",
    "    \n",
    "anomaly_values, projection, geotransform, no_data_value, data_type = calc_anomaly(filepath_agg, filepath_LTA)\n",
    "\n",
    "\n",
    "\n",
    "message = 'Writing anomaly image' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "filename = write_anomaly_output(anomaly_values.data, output_folder, misson_name, stats_name, first_date, last_date, start_year, end_year, None, region_of_interest, name_of_region, projection, geotransform, no_data_value)\n",
    "\n",
    "print(filename)\n",
    "\n",
    "write_properties_file(filename, first_date, last_date, region_of_interest)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
