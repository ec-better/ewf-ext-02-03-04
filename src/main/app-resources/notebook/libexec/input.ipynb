{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-ext-02-03-04 - NDVI anomalies of growing season time series per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI anomalies of growing season time series per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'NDVI anomalies of growing season time series per pixel'),\n",
    "                ('abstract', 'NDVI anomalies of growing season time series per pixel'),\n",
    "                ('id', 'ewf-ext-02-03-04')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON ((-8.864205 38.88616500000001, -8.864205 38.986165, -8.964205000000002 38.986165, -8.964205000000002 38.88616500000001, -8.864205 38.88616500000001))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])\n",
    "\n",
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'P001'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexAndApiKeys = dict([('id', 'indexAndApiKeys'),\n",
    "                        ('value', ''),\n",
    "                        ('title', 'index,apikey pairs'),\n",
    "                        ('abstract', 'index,apikey pairs'),\n",
    "                        ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "Agg and LTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('LE07_difNdvi_P001_2015005_2015020.tif', 'LTA_LE07_difNdvi_P001_005-020_2015-2015.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "Agg and LTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=B02BEB4BAA63351C44F3DF2C9A6D8D116D089325', 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=442355F3238A8B5B9A016D3929ED42FCCF13C236')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aux folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cioppy\n",
    "\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "import datetime\n",
    "\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e) \n",
    "    \n",
    "def get_metadata(filepath):\n",
    "        \n",
    "    #pdb.set_trace()\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "        \n",
    "        print(type(product_array))\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "def get_matrix_list(image_list, mask_value = None):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        \n",
    "        if mask_value is not None:\n",
    "             product_array = np.ma.masked_values (product_array, mask_value)\n",
    "        \n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "\n",
    "def calc_anomaly(agg_file, LTA_file):\n",
    "    \n",
    "    \n",
    "    if agg_file and LTA_file:\n",
    "        \n",
    "        \n",
    "        agg_and_LTA = get_matrix_list([agg_file, LTA_file], -9999.)\n",
    "        print('Aggregation and LTA converted to matrices')\n",
    "                \n",
    "        \n",
    "        #anomaly_values = np.divide(agg_and_LTA[0] * 1.0, agg_and_LTA[1] * 1.0)\n",
    "        \n",
    "      \n",
    "        #anomaly_values = np.divide(agg_and_LTA[0] * 1.0, agg_and_LTA[1] * 1.0, out=np.zeros_like(agg_and_LTA[0]) - 9999.0, where=np.logical_and(agg_and_LTA[1]!=0, agg_and_LTA[0] > -9998, agg_and_LTA[1] > -9998) )\n",
    "        \n",
    "        anomaly_values = np.divide(agg_and_LTA[0] * 1.0, agg_and_LTA[1] * 1.0, out=np.zeros(agg_and_LTA[0].shape) - 9999.0, where=np.logical_and(agg_and_LTA[1]!=0, agg_and_LTA[0] > -9998, agg_and_LTA[1] > -9998) )\n",
    "        \n",
    "        anomaly_values = np.ma.masked_values (anomaly_values, -9999.0)\n",
    "        \n",
    "        #anomaly_values[(agg_and_LTA[0] == 0)] = 0\n",
    "        #anomaly_values[(agg_and_LTA[1] == 0)] = 0\n",
    "        \n",
    "        \n",
    "        #print(anomaly_values.data)\n",
    "        #print(anomaly_values2)\n",
    "        \n",
    "        \n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(agg_file)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #for file_ in file_list:\n",
    "        #    os.remove(file_)\n",
    "        \n",
    "        return anomaly_values, projection, geotransform, no_data_value, data_type\n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    if mask is not None and mask is not 0:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "\n",
    "    \n",
    "\n",
    "def write_anomaly_output(anomaly, output_folder, mission_name, stats_name, first_date, last_date, lta_start_year, lta_end_year, mask_no_value, regionOfInterest, roi_name, projection, geo_transform, no_data_value):\n",
    "    #image_number = (datetime.strptime(last_date, '%Y-%m-%d') - datetime.strptime(first_date, '%Y-%m-%d')).days\n",
    "    \n",
    "    \n",
    "    #filename =  output_folder + '/' + product_name + '_Anomaly_' + roi_name + '_N' + str(N_value) + '_' + aggregation + '_' + first_date + '_' + last_date + '_LTA' + str(lta_start_year) + '_' + str(lta_end_year) + '.tif'\n",
    "    \n",
    "    stats_period = first_date.strftime('%Y%j') + '_' + last_date.strftime('%Y%j')\n",
    "    LTA_period = str(lta_start_year) + '-' + str(lta_end_year)\n",
    "    \n",
    "    filename = '_'.join(['Anomaly', mission_name, stats_name, roi_name, stats_period, 'LTA', LTA_period])\n",
    "    \n",
    "    filename = os.path.join(output_folder, filename + '.tif')\n",
    "    \n",
    "    write_output_image(filename, anomaly, 'GTiff', gdal.GDT_Float32, mask_no_value, projection, geo_transform, no_data_value)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    date = datetime.datetime.strftime(date_str, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#message = 'Getting metadata from catalog' \n",
    "#ciop.log('INFO', message)\n",
    "\n",
    "\n",
    "# organize indexes and apikeys in a python dictionary\n",
    "#indexAndApiKeys_splited = indexAndApiKeys['value'].split(',')\n",
    "#apikeys = {}\n",
    "#for idx,ele in enumerate(indexAndApiKeys_splited):\n",
    "    \n",
    "#    if (idx % 2 == 0):\n",
    "#        print(ele)\n",
    "#        apikeys[ele] = indexAndApiKeys_splited[idx+1]\n",
    "        \n",
    "\n",
    "# get input data from catalog\n",
    "#input_metadata = get_input_metadata (input_references, apikeys)\n",
    "\n",
    "\n",
    "\n",
    "#input_metadata_LTA = input_metadata[input_metadata['title'].str.find('LTA') != -1]\n",
    "#input_metadata_Agg = input_metadata[input_metadata['title'].str.find('LTA') == -1]\n",
    "\n",
    "input_metadata_LTA = input_identifiers[1]\n",
    "input_metadata_Agg = input_identifiers[0]\n",
    "\n",
    "\n",
    "print(input_metadata_LTA, input_metadata_Agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if isinstance(input_identifiers, str):\n",
    "    input_identifiers = [input_identifiers]\n",
    "\n",
    "region_of_interest = regionOfInterest['value']\n",
    "name_of_region = nameOfRegion['value']\n",
    "\n",
    "\n",
    "# get data paths from catalog metadata\n",
    "\n",
    "#filepath_agg = os.path.join(data_path, input_metadata_Agg['enclosure'].iloc[0].split('/')[-1])\n",
    "#filepath_LTA = os.path.join(data_path, input_metadata_LTA['enclosure'].iloc[0].split('/')[-1])\n",
    "\n",
    "filepath_agg = os.path.join(data_path, input_metadata_Agg)\n",
    "filepath_LTA = os.path.join(data_path, input_metadata_LTA)\n",
    "\n",
    "\n",
    "print(filepath_agg)\n",
    "print(filepath_LTA)\n",
    "\n",
    "\n",
    "\n",
    "# get metadata from catalog metadata (Agg and LTA)\n",
    "\n",
    "# Agg\n",
    "\n",
    "file_name_elements = os.path.basename(filepath_agg).split('.')[0].split('_')\n",
    "#['LST', 'SouthernAfrica', 'N3', 'averages', '2015-01-01', '2015-01-21']\n",
    "#first_date = file_name_elements[-2]\n",
    "#last_date = file_name_elements[-1]\n",
    "misson_name = file_name_elements[0]\n",
    "stats_name = file_name_elements[1]\n",
    "aoi_name = file_name_elements[2]\n",
    "\n",
    "#LE07_difNdvi_P001_2015005_2015020.tif\n",
    "print(misson_name, stats_name, aoi_name)\n",
    "\n",
    "#first_date = input_metadata_Agg['startdate'].iloc[0].strftime('%Y-%m-%d')\n",
    "#last_date = input_metadata_Agg['enddate'].iloc[0].strftime('%Y-%m-%d')\n",
    "\n",
    "first_date = datetime.datetime.strptime(file_name_elements[3], \"%Y%j\")\n",
    "last_date = datetime.datetime.strptime(file_name_elements[4], \"%Y%j\")\n",
    "\n",
    "\n",
    "#first_date = first_date.strftime('%Y-%m-%d')\n",
    "#last_date = last_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(first_date)\n",
    "print(last_date)\n",
    "\n",
    "\n",
    "# LTA\n",
    "\n",
    "file_name_elements = os.path.basename(filepath_LTA).split('.')[0].split('_')\n",
    "\n",
    "\n",
    "#start_year = str(input_metadata_LTA['startdate'].iloc[0].year)\n",
    "#end_year = str(input_metadata_LTA['enddate'].iloc[0].year)\n",
    "\n",
    "start_year = file_name_elements[5].split('-')[0]\n",
    "end_year = file_name_elements[-1].split('-')[1]\n",
    "\n",
    "print(file_name_elements)\n",
    "#['LTA', 'LE07', 'difNdvi', 'P001', '005-020', '2015-2015']\n",
    "\n",
    "stats_name_LTA = file_name_elements[2]\n",
    "\n",
    "\n",
    "print(start_year)\n",
    "print(end_year)\n",
    "\n",
    "\n",
    "\n",
    "print(filepath_agg)\n",
    "print(filepath_LTA)        \n",
    "\n",
    "message = 'Computing Anomaly' \n",
    "ciop.log('INFO', message)\n",
    "    \n",
    "    \n",
    "anomaly_values, projection, geotransform, no_data_value, data_type = calc_anomaly(filepath_agg, filepath_LTA)\n",
    "\n",
    "\n",
    "\n",
    "message = 'Writing anomaly image' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "filename = write_anomaly_output(anomaly_values.data, output_folder, misson_name, stats_name, first_date, last_date, start_year, end_year, None, region_of_interest, name_of_region, projection, geotransform, no_data_value)\n",
    "\n",
    "print(filename)\n",
    "\n",
    "write_properties_file(filename, first_date, last_date, region_of_interest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(anomaly_values)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vacc-env2",
   "language": "python",
   "name": "vacc-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
